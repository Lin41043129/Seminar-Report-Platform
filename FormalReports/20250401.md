# 📝 演講書面報告

## 👦 學生
四資工四甲 41043129 林傳勝
## 📅 日期
2025年4月1日
## 🎙️ 講者
中央研究院資訊科學研究所 特聘研究員 廖弘源博士
## 📝 題目
YOLOv4、YOLOv7 及 YOLOv9 的發展過程

## 💡 心得報告

廖弘源博士的演講介紹了YOLO系列對物件偵測系統的發展歷程。廖博士首先介紹了電腦視覺領域的發展困境。對人類來說簡單的影像辨識任務，對電腦而言卻非常困難，因為電腦只能看到一堆數字。直到2010年，普林斯頓大學的研究團隊利用1400萬張影像訓練出了一本「視覺字典」，才讓電腦視覺領域有突破性的進展。

YOLO系列的發展始於2015年，由Joseph Redmon開發了第一代「You Only Look Once」一階段物件偵測系統。由於擔心技術被用於軍事用途，Redmon在YOLOv3後停止了研發。廖博士則持不同看法，認為這類技術也能用於防禦，保護國家安全。因此，從2020年開始，廖博士團隊接續開發了YOLOv4、YOLOv7和YOLOv9，使台灣在即時物件偵測系統領域領先其他國家。

YOLOv4的核心創新在於CSP (Cross Stage Partial Network)結構，它通過將特徵圖分成兩部分並行處理，能在減少計算量的同時提高準確率。廖博士詳細解釋了CSP的設計理念：最初他們嘗試在七層的CNN中實現資料分流，但效果不佳；後來發現必須在stage level（包含多層卷積的功能單元）實現CSP才能成功。因為一個stage是最小能夠帶有語意的單位，在此層級進行分流才有意義。通過這種設計，YOLOv4在保持高準確率的同時，將計算量減少了20%，記憶體使用減少了30%，使其在邊緣裝置上也能高效運行。廖博士還展示了與當時其他模型的比較，證明YOLOv4在速度與準確率的平衡上達到了最佳表現。

YOLOv7則引入了E-ELAN (Extended Efficient Layer Aggregation Network)架構和implicit knowledge的概念，進一步提升了運行速度和準確率。E-ELAN通過擴展和重組計算圖，實現了更高效率的特徵融合。implicit knowledge的概念廖博士則是以數學考試為例，解釋到就像學生在考試中能解出課本中沒有直接教授的題目，神經網路中也存在未被明確訓練但可以被發掘的知識。YOLOv7通過特殊的參數重參數化技術，在訓練時使用一組參數，推論時轉換為另一組參數，有效地挖掘了網路中的隱含知識。這種方法不僅提高了模型性能，還大幅減少了訓練時間，使YOLOv7在同等準確率下比YOLOv4快約40%，且參數量減少了75%，成為當時最高效的物件偵測系統。廖博士還展示了YOLOv7在各種硬體平台上的表現數據，證明其在從高端GPU到移動裝置的各種環境中都具有優秀性能。

最新的YOLOv9解決了深層網路中資料流失的問題。廖博士解釋，在深層網路中，資料經過多層矩陣運算後會逐漸流失，到第150層時幾乎完全失真。YOLOv9通過創新的PGI (Programmable Gradient Information)技術和可逆分支(reversible branch)架構，在訓練過程中保持資料完整性。PGI和可逆分支機制只在訓練時使用，推論時可移除，因此不會增加運算負擔。使得YOLOv9即使在極深的網路層次中也能保持資料清晰，大幅提升了物件偵測的準確性。

接著廖博士展示了YOLO系列在多個領域的應用，包括智慧交通系統、國防安全偵測、農業害蟲防治和醫學影像分析。廖博士展示了一個使用雷射結合YOLOv7即時偵測並消除果樹害蟲的系統，每秒可處理150隻害蟲，大幅提升農業效率。也展示YOLOv9的多模型(M-model)設計能讓單一骨幹網路同時處理物件偵測、分割和影像描述等多項任務，為視障人士提供環境描述等服務。

在學術影響力方面，廖博士分享YOLOv4在2020年全球AI論文引用排名中位於第三，僅次於Google的Vision Transformer和OpenAI的GPT-3；而CSPNet論文已被引用超過5000次，YOLOv7超過10000次，YOLOv9雖發表僅一年多，已接近1900次引用，讓台灣在國際AI研究領域嶄露頭角。

演講最後，廖博士分享了他對研究生的建議：要追求科學的核心，不只是湊合系統就畢業，而是要深入思考問題的本質。「過簡單的生活，但用複雜的思考面對問題」，只有生活簡單，頭腦才能清晰；只有思考複雜，才能解決困難問題。

## 🔑 關鍵字
YOLO系列、物件偵測、CSP架構、E-ELAN、PGI、即時偵測

## 📖 參考文獻
1. Wang, C. Y., Bochkovskiy, A., & Liao, H. Y. M. (2020). YOLOv4: Optimal Speed and Accuracy of Object Detection. arXiv preprint arXiv:2004.10934.
2. Wang, C. Y., Yeh, I. H., & Liao, H. Y. M. (2021). CSPNet: A New Backbone that can Enhance Learning Capability of CNN. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops.
3. Wang, C. Y., Liao, H. Y. M., Wu, Y. H., Chen, P. Y., Hsieh, J. W., & Yeh, I. H. (2023). YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.
4. Wang, C. Y., Liao, H. Y. M., & Yeh, I. H. (2024). YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information. arXiv preprint arXiv:2402.13616.